{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import schedules\n",
    "from dataset import get_data, normalize\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.python.keras.layers import Input, Dense, Lambda, Conv2D, Conv2DTranspose, Flatten, Reshape\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.losses import binary_crossentropy\n",
    "from tensorflow.python.keras.optimizers import adam_v2\n",
    "from tensorflow.python.keras import backend as K\n",
    "from skimage.transform import resize\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def encoder(input_shape, latent_dim):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(filters=32, kernel_size=3, strides=2, activation='relu', padding='same')(inputs)\n",
    "    x = Conv2D(filters=64, kernel_size=3, strides=2, activation='relu', padding='same')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "\n",
    "    z_mean = Dense(latent_dim)(x)\n",
    "    z_log_var = Dense(latent_dim)(x)\n",
    "\n",
    "    return Model(inputs, [z_mean, z_log_var], name='encoder')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def decoder(latent_dim):\n",
    "    inputs = Input(shape=latent_dim)\n",
    "    x = Dense(8 * 8 * 64, activation='relu')(inputs)\n",
    "    x = Reshape((8, 8, 64))(x)\n",
    "    x = Conv2DTranspose(filters=64, kernel_size=3, strides=2, activation='relu', padding='same')(x)\n",
    "    x = Conv2DTranspose(filters=32, kernel_size=3, strides=2, activation='relu', padding='same')(x)\n",
    "    outputs = Conv2DTranspose(filters=3, kernel_size=3, strides=1, activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    return Model(inputs, outputs, name='decoder')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsl = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsl"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def vae_loss(x, x_decode_mean, z_mean, z_log_var):\n",
    "    rec_loss = binary_crossentropy(K.flatten(x), K.flatten(x_decode_mean)) * 32 * 32 * 3\n",
    "    kl_loss = -0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    return K.mean(rec_loss + kl_loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    ######################## Get train dataset ########################\n",
    "    X_train = get_data('dataset')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "    input_shape = (32, 32, 3)\n",
    "    latent_dim = 64"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "    encoder = encoder(input_shape, latent_dim)\n",
    "    decoder = decoder(latent_dim)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "    inputs = Input(shape=input_shape)\n",
    "    z_mean, z_log_var = encoder(inputs)\n",
    "    z = Lambda(sampling)([z_mean, z_log_var])\n",
    "    outputs = decoder(z)\n",
    "\n",
    "    vae = Model(inputs, outputs, name='vae')\n",
    "\n",
    "    loss = vae_loss(inputs, outputs, z_mean, z_log_var)\n",
    "    vae.add_loss(loss)\n",
    "    vae_optimizer = adam_v2.Adam(learning_rate=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "    X_train = normalize(X_train)\n",
    "    X_train = np.transpose(X_train, (0, 2, 3, 1)) #使shape匹配\n",
    "    # print(X_train.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "    epochs = 100\n",
    "    batch_size = 32\n",
    "    decay_steps = 10000\n",
    "    decay_rate = 0.9"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 1926.367\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 10\u001B[0m\n\u001B[0;32m      7\u001B[0m     x_decoded \u001B[38;5;241m=\u001B[39m decoder(z)\n\u001B[0;32m      8\u001B[0m     loss_value \u001B[38;5;241m=\u001B[39m vae_loss(x_batch, x_decoded, z_mean, z_log_var)\n\u001B[1;32m---> 10\u001B[0m gradients \u001B[38;5;241m=\u001B[39m \u001B[43mtape\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgradient\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloss_value\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvae\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainable_variables\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m vae_optimizer\u001B[38;5;241m.\u001B[39mapply_gradients(\u001B[38;5;28mzip\u001B[39m(gradients, vae\u001B[38;5;241m.\u001B[39mtrainable_variables))\n\u001B[0;32m     13\u001B[0m current_step \u001B[38;5;241m=\u001B[39m epoch \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mlen\u001B[39m(X_train) \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m batch_size \u001B[38;5;241m+\u001B[39m i \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m batch_size\n",
      "File \u001B[1;32mf:\\python\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1063\u001B[0m, in \u001B[0;36mGradientTape.gradient\u001B[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001B[0m\n\u001B[0;32m   1057\u001B[0m   output_gradients \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m   1058\u001B[0m       composite_tensor_gradient\u001B[38;5;241m.\u001B[39mget_flat_tensors_for_gradients(\n\u001B[0;32m   1059\u001B[0m           output_gradients))\n\u001B[0;32m   1060\u001B[0m   output_gradients \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m x \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mconvert_to_tensor(x)\n\u001B[0;32m   1061\u001B[0m                       \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m output_gradients]\n\u001B[1;32m-> 1063\u001B[0m flat_grad \u001B[38;5;241m=\u001B[39m \u001B[43mimperative_grad\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimperative_grad\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1064\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tape\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1065\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_targets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1066\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_sources\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1067\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_gradients\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_gradients\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1068\u001B[0m \u001B[43m    \u001B[49m\u001B[43msources_raw\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mflat_sources_raw\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1069\u001B[0m \u001B[43m    \u001B[49m\u001B[43munconnected_gradients\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43munconnected_gradients\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1071\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_persistent:\n\u001B[0;32m   1072\u001B[0m   \u001B[38;5;66;03m# Keep track of watched variables before setting tape to None\u001B[39;00m\n\u001B[0;32m   1073\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_watched_variables \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tape\u001B[38;5;241m.\u001B[39mwatched_variables()\n",
      "File \u001B[1;32mf:\\python\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:67\u001B[0m, in \u001B[0;36mimperative_grad\u001B[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001B[0m\n\u001B[0;32m     63\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n\u001B[0;32m     64\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m     65\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnknown value for unconnected_gradients: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m unconnected_gradients)\n\u001B[1;32m---> 67\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_TapeGradient\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     68\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtape\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[0;32m     69\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     70\u001B[0m \u001B[43m    \u001B[49m\u001B[43msources\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     71\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_gradients\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     72\u001B[0m \u001B[43m    \u001B[49m\u001B[43msources_raw\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     73\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mas_str\u001B[49m\u001B[43m(\u001B[49m\u001B[43munconnected_gradients\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mf:\\python\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:146\u001B[0m, in \u001B[0;36m_gradient_function\u001B[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001B[0m\n\u001B[0;32m    144\u001B[0m     gradient_name_scope \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m forward_pass_name_scope \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    145\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mname_scope(gradient_name_scope):\n\u001B[1;32m--> 146\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgrad_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmock_op\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mout_grads\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    147\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    148\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m grad_fn(mock_op, \u001B[38;5;241m*\u001B[39mout_grads)\n",
      "File \u001B[1;32mf:\\python\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py:582\u001B[0m, in \u001B[0;36m_Conv2DGrad\u001B[1;34m(op, grad)\u001B[0m\n\u001B[0;32m    573\u001B[0m shape_0, shape_1 \u001B[38;5;241m=\u001B[39m array_ops\u001B[38;5;241m.\u001B[39mshape_n([op\u001B[38;5;241m.\u001B[39minputs[\u001B[38;5;241m0\u001B[39m], op\u001B[38;5;241m.\u001B[39minputs[\u001B[38;5;241m1\u001B[39m]])\n\u001B[0;32m    575\u001B[0m \u001B[38;5;66;03m# We call the gen_nn_ops backprop functions instead of nn_ops backprop\u001B[39;00m\n\u001B[0;32m    576\u001B[0m \u001B[38;5;66;03m# functions for performance reasons in Eager mode. gen_nn_ops functions take a\u001B[39;00m\n\u001B[0;32m    577\u001B[0m \u001B[38;5;66;03m# `explicit_paddings` parameter, but nn_ops functions do not. So if we were\u001B[39;00m\n\u001B[0;32m    578\u001B[0m \u001B[38;5;66;03m# to use the nn_ops functions, we would have to convert `padding` and\u001B[39;00m\n\u001B[0;32m    579\u001B[0m \u001B[38;5;66;03m# `explicit_paddings` into a single `padding` parameter, increasing overhead\u001B[39;00m\n\u001B[0;32m    580\u001B[0m \u001B[38;5;66;03m# in Eager mode.\u001B[39;00m\n\u001B[0;32m    581\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[1;32m--> 582\u001B[0m     \u001B[43mgen_nn_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d_backprop_input\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    583\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshape_0\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    584\u001B[0m \u001B[43m        \u001B[49m\u001B[43mop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    585\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    586\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdilations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdilations\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    587\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstrides\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstrides\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    588\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    589\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexplicit_paddings\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexplicit_paddings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    590\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cudnn_on_gpu\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cudnn_on_gpu\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    591\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_format\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[0;32m    592\u001B[0m     gen_nn_ops\u001B[38;5;241m.\u001B[39mconv2d_backprop_filter(\n\u001B[0;32m    593\u001B[0m         op\u001B[38;5;241m.\u001B[39minputs[\u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m    594\u001B[0m         shape_1,\n\u001B[0;32m    595\u001B[0m         grad,\n\u001B[0;32m    596\u001B[0m         dilations\u001B[38;5;241m=\u001B[39mdilations,\n\u001B[0;32m    597\u001B[0m         strides\u001B[38;5;241m=\u001B[39mstrides,\n\u001B[0;32m    598\u001B[0m         padding\u001B[38;5;241m=\u001B[39mpadding,\n\u001B[0;32m    599\u001B[0m         explicit_paddings\u001B[38;5;241m=\u001B[39mexplicit_paddings,\n\u001B[0;32m    600\u001B[0m         use_cudnn_on_gpu\u001B[38;5;241m=\u001B[39muse_cudnn_on_gpu,\n\u001B[0;32m    601\u001B[0m         data_format\u001B[38;5;241m=\u001B[39mdata_format)\n\u001B[0;32m    602\u001B[0m ]\n",
      "File \u001B[1;32mf:\\python\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py:1764\u001B[0m, in \u001B[0;36mconv2d_backprop_input\u001B[1;34m(input_sizes, filter, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001B[0m\n\u001B[0;32m   1762\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tld\u001B[38;5;241m.\u001B[39mis_eager:\n\u001B[0;32m   1763\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1764\u001B[0m     _result \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_FastPathExecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1765\u001B[0m \u001B[43m      \u001B[49m\u001B[43m_ctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mConv2DBackpropInput\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_sizes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mfilter\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout_backprop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1766\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrides\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstrides\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muse_cudnn_on_gpu\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_cudnn_on_gpu\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpadding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1767\u001B[0m \u001B[43m      \u001B[49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mexplicit_paddings\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexplicit_paddings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdata_format\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1768\u001B[0m \u001B[43m      \u001B[49m\u001B[43mdata_format\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdilations\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdilations\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1769\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[0;32m   1770\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "    for epoch in range(epochs):\n",
    "        for i in range(0, len(X_train), batch_size):\n",
    "            x_batch = X_train[i:i + batch_size]\n",
    "            with tf.GradientTape() as tape:\n",
    "                z_mean, z_log_var = encoder(x_batch)\n",
    "                z = sampling([z_mean, z_log_var])\n",
    "                x_decoded = decoder(z)\n",
    "                loss_value = vae_loss(x_batch, x_decoded, z_mean, z_log_var)\n",
    "\n",
    "            gradients = tape.gradient(loss_value, vae.trainable_variables)\n",
    "            vae_optimizer.apply_gradients(zip(gradients, vae.trainable_variables))\n",
    "\n",
    "            current_step = epoch * len(X_train) // batch_size + i // batch_size\n",
    "            current_learning_rate = 0.001 * decay_rate ** (current_step / decay_steps)\n",
    "            vae_optimizer.learning_rate.assign(current_learning_rate)\n",
    "\n",
    "        print('Epoch:', epoch + 1, 'Loss:', loss_value.numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    idx = 999"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    path = \"./reconstructed/\"\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    x = np.expand_dims(X_train[idx], axis=0)\n",
    "    x_reconstructed = vae.predict(x)\n",
    "    x_reconstructed = np.clip(x_reconstructed, 0.0, 1.0)\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(x[0])\n",
    "    plt.axis('off')\n",
    "    plt.title('Original Image')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(x_reconstructed[0])\n",
    "    plt.axis('off')\n",
    "    plt.title('Reconstructed Image')\n",
    "    plt.savefig(path + \"rec.png\")\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "    def interpolate_images(image1, image2, num_interpolations):\n",
    "        z1, _ = encoder.predict(np.expand_dims(image1, axis=0))\n",
    "        z2, _ = encoder.predict(np.expand_dims(image2, axis=0))\n",
    "\n",
    "        interpolated_images = []\n",
    "        for i in range(num_interpolations + 1):\n",
    "            alpha = i / num_interpolations\n",
    "            z_interpolated = alpha * z1 + (1 - alpha) * z2\n",
    "            img_interpolated = decoder.predict(z_interpolated)\n",
    "            interpolated_images.append(img_interpolated)\n",
    "            # if i == 0 or i == int(num_interpolations / 2) or i == num_interpolations:\n",
    "            #     interpolated_images.append(img_interpolated)\n",
    "\n",
    "        return interpolated_images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    images = []\n",
    "    path = \"./random_6x6/\"\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    for cnt in range(10):\n",
    "        current_images = []\n",
    "\n",
    "        for _ in range(6):\n",
    "            i1 = random.randint(0, 999)\n",
    "            i2 = random.randint(0, 999)\n",
    "            image1 = X_train[i1]\n",
    "            image2 = X_train[i2]\n",
    "\n",
    "            interpolated_images = interpolate_images(image1, image2, 5)\n",
    "            current_images.extend(interpolated_images)\n",
    "\n",
    "        images.append(current_images)\n",
    "\n",
    "    for cnt, image_set in enumerate(images):\n",
    "        fig, axes = plt.subplots(6, 6, figsize=(20, 20))\n",
    "\n",
    "        for i, img in enumerate(image_set):\n",
    "            ax = axes[i // 6, i % 6]\n",
    "            ax.imshow(np.squeeze(img))\n",
    "            ax.axis('off')\n",
    "\n",
    "        plt.savefig(\"./random_6x6/\" + str(cnt) + \".png\")\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}